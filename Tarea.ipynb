{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "- Trabajo de la asignatura INFO343 …\n",
    "- Breve descripción del desafío y los datos\n",
    "\n",
    "### Desafío\n",
    "- Descripción incluyendo autores, año, institución, paper en el que se describe, etc.\n",
    "- https://arxiv.org/pdf/1807.09902\n",
    "\n",
    "### Datos\n",
    "- Cuantos datos hay\n",
    "- Cuantas clases distintas hay\n",
    "- Cuantos datos están verificados\n",
    "- Como se estructuran (carpeta test y train)\n",
    "- Ejemplo de 1 espectrograma de cada clase\n",
    "\n",
    "### Solución\n",
    "- Paper\n",
    "- Autores\n",
    "- año\n",
    "- Score\n",
    "- https://dcase.community/documents/challenge2018/technical_reports/DCASE2018_Baseline_87.pdf\n",
    "\n",
    "### Código\n",
    "- Como ejecutar\n",
    "- Estructura del código\n",
    "- Archivos auxiliares\n",
    "\t- Funciones de cada archivo\n",
    "- Modelo\n",
    "\t- Arquitectura\n",
    "\t- Explicación\n",
    "- Código del modelo\n",
    "- Ejecutar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código\n",
    "\n",
    "El código que implementa el artículo descrito anteriormente se encuentra en el siguiente repositorio:\n",
    "\n",
    "[Repositorio en GitHub](https://github.com/qiuqiangkong/dcase2018_task2/tree/master)\n",
    "\n",
    "Además, este código está incluido en la carpeta \"Código de referencia\" del repositorio utilizado para este trabajo.\n",
    "\n",
    "La Figura X muestra la estructura del código, que se compone principalmente de las siguientes carpetas y archivos:\n",
    "\n",
    "- **utils**: Contiene funciones auxiliares, variables de configuración y scripts para crear los datos necesarios para el entrenamiento y validación del modelo.\n",
    "- **pytorch**: Incluye el código de los modelos descritos anteriormente y la función que ejecuta el entrenamiento y validación.\n",
    "- **runme.sh**: Archivo encargado de ejecutar el código en secuencia.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./Imagenes/Estructura.png\" alt=\"Estructura del Código\" height=\"600\">\n",
    "    <p><em>Figura X: Estructura del repositorio.</em></p>\n",
    "</div>\n",
    "\n",
    "Este repositorio también incluye instrucciones sobre cómo ejecutar el código. Sin embargo, en el presente trabajo, este código se ha readaptado para ejecutarse mediante un Jupyter Notebook y para que funcione con versiones más recientes de las librerías utilizadas. Por lo tanto, todos los archivos del código de referencia están descritos en este notebook, pero serán presentados según su distribución en los archivos del código de referencia.\n",
    "\n",
    "## Librerías\n",
    "\n",
    "Para ejecutar el código en este trabajo, se deben instalar las librerías descritas en el archivo `requirements.txt`. Estas se han actualizado del código original a las siguientes versiones:\n",
    "\n",
    "- **matplotlib**: 2.2.2 -> 3.9.1\n",
    "- **numpy**: 1.14.5 -> 1.26.4\n",
    "- **h5py**: 2.8.0 -> 3.11.0\n",
    "- **pytorch**: 0.4.0 -> 2.3.1\n",
    "- **librosa**: 0.6.1 -> 0.10.2\n",
    "- **scikit-learn**: 0.19.1 -> 1.5.1\n",
    "- **soundfile**: 0.10.2 -> 0.12.1\n",
    "\n",
    "A continuación se encuentran todas las importaciones necesarias para la ejecución del programa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos y funciones presentes en la carpeta `utils` son los siguientes:\n",
    "\n",
    "### utilities.py\n",
    "\n",
    "Implementa las siguientes funciones auxiliares:\n",
    "\n",
    "- **create_folder**: Crea un directorio si no existe.\n",
    "- **get_filename**: Devuelve el nombre de un archivo a partir de una ruta y sin la extensión. Sin embargo, no es utilizada para la ejecución de esta tarea.\n",
    "- **create_logging**: Crea un directorio para logs, un archivo de log numerado, y configura la salida del log tanto en archivo como en consola. Sin embargo, no es utilizada para la ejecución de esta tarea.\n",
    "- **read_audio**: Lee un archivo de audio y, opcionalmente, lo resamplea a una frecuencia objetivo (variable `target_fs`).\n",
    "- **calculate_scalar**: Calcula la media y la desviación estándar de un arreglo.\n",
    "- **scale**: Normaliza un arreglo usando la media y la desviación estándar proporcionadas.\n",
    "- **inverse_scale**: Desnormaliza un arreglo utilizando la media y la desviación estándar proporcionadas. Sin embargo, no es utilizada para la ejecución de esta tarea.\n",
    "- **repeat_seq**: Repite varias veces una lista hasta que tenga una longitud de `time_steps`. Luego, corta la lista repetida para que su longitud sea exactamente `time_steps` y la devuelve.\n",
    "- **calculate_accuracy**: Calcula el Accuracy de la clasificación comparando las predicciones con las etiquetas reales.\n",
    "- **print_class_wise_accuracy**: Imprime y retorna el Accuracy por clase.\n",
    "- **plot_class_wise_accuracy**: Grafica el Accuracy por clase. Sin embargo, no es utilizada para la ejecución de esta tarea.\n",
    "- **write_testing_data_submission_csv**: Escribe los resultados al probar el modelo en un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(fd):\n",
    "    if not os.path.exists(fd):\n",
    "        os.makedirs(fd)\n",
    "   \n",
    "def read_audio(path, target_fs=None):\n",
    "    (audio, fs) = soundfile.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "    return audio, fs\n",
    "\n",
    "def calculate_scalar(x):\n",
    "    if x.ndim == 2:\n",
    "        axis = 0\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1)\n",
    "    mean = np.mean(x, axis=axis)\n",
    "    std = np.std(x, axis=axis)\n",
    "    return mean, std\n",
    "\n",
    "def scale(x, mean, std):\n",
    "    return (x - mean) / std\n",
    "\n",
    "def repeat_seq(x, time_steps):\n",
    "    repeat_num = time_steps // len(x) + 1\n",
    "    repeat_x = np.tile(x, (repeat_num, 1))[0 : time_steps]\n",
    "    return repeat_x\n",
    "    \n",
    "def calculate_accuracy(output, target):\n",
    "    acc = np.sum(output == target) / float(len(target))\n",
    "    return acc\n",
    "    \n",
    "def print_class_wise_accuracy(output, target):\n",
    "    \"\"\"Print class wise accuracy.\"\"\"\n",
    "    global labels\n",
    "    global ix_to_lb\n",
    "    correctness = np.zeros(len(labels), dtype=np.int32)\n",
    "    total = np.zeros(len(labels), dtype=np.int32)\n",
    "    for n in range(len(target)):\n",
    "        total[target[n]] += 1\n",
    "        if output[n] == target[n]:\n",
    "            correctness[target[n]] += 1\n",
    "    class_wise_accuracy = correctness.astype(np.float32) / total\n",
    "    logging.info('{:<30}{}/{}\\t{}'.format(\n",
    "        'event labels', 'correct', 'total', 'accuracy'))\n",
    "    for (n, label) in enumerate(labels):\n",
    "        logging.info('{:<30}{}/{}\\t\\t{:.2f}'.format(\n",
    "            label, correctness[n], total[n], class_wise_accuracy[n]))\n",
    "    class_wise_accuracy = np.array(class_wise_accuracy)\n",
    "    return class_wise_accuracy, correctness, total\n",
    "\n",
    "def write_testing_data_submission_csv(submission_path, audio_names, \n",
    "                                      sorted_indices):\n",
    "    global kmax\n",
    "    global ix_to_lb\n",
    "    global corrupted_files\n",
    "    # Write result to submission csv\n",
    "    f = open(submission_path, 'w')\n",
    "    f.write('fname,label\\n')\n",
    "    for (n, audio_name) in enumerate(audio_names):\n",
    "        f.write('{},'.format(audio_name))\n",
    "        predicted_labels = [ix_to_lb[sorted_indices[n, k]] for k in range(kmax)]\n",
    "        f.write(' '.join(predicted_labels)) \n",
    "        f.write('\\n')\n",
    "    for audio_name in corrupted_files:\n",
    "        f.write('{},{}\\n'.format(audio_name, 'Acoustic_guitar'))\n",
    "    f.close()\n",
    "    print(\"Write result to {}\".format(submission_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average_precision.py\n",
    "\n",
    "Este archivo implementa funciones para evaluar la precisión del modelo:\n",
    "\n",
    "- **apk**: Calcula la precisión promedio de las primeras k predicciones (por defecto, los primeros 10 elementos).\n",
    "\n",
    "- **mapk**: Extiende la función `apk` a múltiples listas, calculando la precisión promedio de las primeras k predicciones para cada lista y luego promediando estos valores (por defecto, los primeros 10 elementos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_generator.py\n",
    "\n",
    "Este archivo contiene una clase `DataGenerator` que se utiliza para generar datos para entrenar y validar el modelo y la clase `TestDataGenerator` para generar datos de prueba. Las descripciones de los métodos de estas clases son las siguientes:\n",
    "\n",
    "#### Clase `DataGenerator`\n",
    "- **`__init__`**: Inicializa la clase con los parámetros dados, carga los datos desde un archivo HDF5 y calcula las estadísticas para la normalización.\n",
    "- **`get_audio_indexes`**: Obtiene los índices de los audios de entrenamiento y validación a partir del archivo CSV de validación.\n",
    "- **`calculate_training_data_scalar`**: Calcula la media y la desviación estándar de los datos de entrenamiento.\n",
    "- **`calculate_patch_bgn_fin_y_tuples`**: Calcula las posiciones de inicio y fin de los segmentos de audio, de los datos de entrenamiento.\n",
    "- **`get_patch_bgn_fin_y_tuples_for_an_audio`**: Calcula las posiciones de inicio y fin del segmentos de un audio.\n",
    "- **`generate_train`**: Genera lotes de datos para el entrenamiento.\n",
    "- **`get_batch_x_y`**: Obtiene los datos de entrada y las etiquetas para un lote (batch).\n",
    "- **`generate_validate_slices`**: Genera lotes de datos para la validación del modelo.\n",
    "- **`transform`**: Normaliza los datos.\n",
    "\n",
    "#### Clase `TestDataGenerator`\n",
    "- **`__init__`**: Inicializa la clase con los parámetros dados, carga los datos desde un archivo HDF5 y hereda los métodos de la clase `DataGenerator` (mediante *super(TestDataGenerator, self)*).\n",
    "- **`generate_test_slices`**: Itera sobre los índices de los audios de prueba y genera lotes de datos normalizados junto con los nombres de los audios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    \n",
    "    def __init__(self, hdf5_path, batch_size, time_steps, \n",
    "        validation_csv=None, holdout_fold=None, seed=1234):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          hdf5_path: str, path of hdf5 data\n",
    "          batch_size: int\n",
    "          time_stes: int, number of frames of a logmel spectrogram patch\n",
    "          validate_csv: string | None, if None then use all data for training\n",
    "          holdout_fold: int\n",
    "          seed: int, random seed\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.random_state = np.random.RandomState(seed)\n",
    "        self.validate_random_state = np.random.RandomState(0)\n",
    "        global labels\n",
    "        self.labels = labels\n",
    "        global lb_to_ix\n",
    "        self.time_steps = time_steps\n",
    "        self.hop_frames = self.time_steps // 2\n",
    "        self.classes_num = len(self.labels)\n",
    "        # Load data\n",
    "        load_time = time.time()\n",
    "        hf = h5py.File(hdf5_path, 'r')\n",
    "        self.audio_names = np.array([s.decode() for s in hf['filename'][:]])\n",
    "        self.x = hf['feature'][:]\n",
    "        self.bgn_fin_indices = hf['bgn_fin_indices'][:]\n",
    "        event_labels = hf['label'][:]\n",
    "        self.y = np.array([lb_to_ix[s.decode()] for s in event_labels])\n",
    "        self.manually_verifications = hf['manually_verification'][:]\n",
    "        hf.close()\n",
    "        logging.info('Loading data time: {:.3f} s'.format(\n",
    "            time.time() - load_time))\n",
    "        # Load validation\n",
    "        if validation_csv:\n",
    "            self.train_audio_indexes, self.validate_audio_indexes = \\\n",
    "                self.get_audio_indexes(validation_csv, holdout_fold)\n",
    "        else:\n",
    "            self.train_audio_indexes = np.arange(len(self.audio_names))\n",
    "            self.validate_audio_indexes = np.array([])                  \n",
    "        logging.info('Training audios number: {}'.format(\n",
    "            len(self.train_audio_indexes)))\n",
    "        logging.info('Validation audios number: {}'.format(\n",
    "            len(self.validate_audio_indexes)))         \n",
    "        # calculate scalar\n",
    "        (self.mean, self.std) = self.calculate_training_data_scalar()\n",
    "        # Get training patches\n",
    "        self.train_patch_bgn_fin_y_tuples = \\\n",
    "            self.calculate_patch_bgn_fin_y_tuples(self.train_audio_indexes)\n",
    "        logging.info('Training patches number: {}'.format(\n",
    "            len(self.train_patch_bgn_fin_y_tuples)))\n",
    "    \n",
    "    def get_audio_indexes(self, validation_csv, holdout_fold):\n",
    "        \"\"\"Get train and audio indexes from validation csv. \n",
    "        \"\"\"\n",
    "        df = pd.read_csv(validation_csv, sep=',')\n",
    "        df = pd.DataFrame(df)\n",
    "        folds = df['fold']\n",
    "        train_audio_indexes = np.where(folds != holdout_fold)[0]\n",
    "        validate_audio_indexes = np.where(folds == holdout_fold)[0]\n",
    "        return train_audio_indexes, validate_audio_indexes\n",
    "\n",
    "    def calculate_training_data_scalar(self):\n",
    "        \"\"\"Concatenate all training data and calculate scalar. \n",
    "        \"\"\"\n",
    "        train_bgn_fin_indices = self.bgn_fin_indices[self.train_audio_indexes]\n",
    "        train_x_concat = []\n",
    "        for [bgn, fin] in train_bgn_fin_indices:\n",
    "            train_x_concat.append(self.x[bgn : fin]) \n",
    "        train_x_concat = np.concatenate(train_x_concat, axis=0)\n",
    "        (mean, std) = calculate_scalar(train_x_concat)\n",
    "        return mean, std\n",
    "\n",
    "    def calculate_patch_bgn_fin_y_tuples(self, audio_indexes):\n",
    "        \"\"\"Calculate (bgn, fin, y) tuples for selecting patches for training. \n",
    "        \"\"\"\n",
    "        bgn_fin_indices = self.bgn_fin_indices[audio_indexes]\n",
    "        patch_bgn_fin_y_tuples = []\n",
    "        for n in range(len(audio_indexes)):\n",
    "            [bgn, fin] = bgn_fin_indices[n]\n",
    "            y = self.y[audio_indexes[n]]\n",
    "            patch_tuples_for_this_audio = \\\n",
    "                self.get_patch_bgn_fin_y_tuples_for_an_audio(bgn, fin, y)  \n",
    "            patch_bgn_fin_y_tuples += patch_tuples_for_this_audio\n",
    "        # Print class wise number of patches\n",
    "        patches_per_class = np.zeros(self.classes_num, dtype=np.int32)\n",
    "        for k in range(self.classes_num):\n",
    "            patches_per_class[k] = np.sum(\n",
    "                [tuple[2] == k for tuple in patch_bgn_fin_y_tuples])\n",
    "        if False:\n",
    "            for k in range(self.classes_num):\n",
    "                logging.info('{:<30}{}'.format(\n",
    "                    self.labels[k], patches_per_class[k]))\n",
    "        return patch_bgn_fin_y_tuples\n",
    "\n",
    "    def get_patch_bgn_fin_y_tuples_for_an_audio(self, bgn, fin, y):\n",
    "        \"\"\"Get (bgn, fin, y) tuples in an audio. \n",
    "        \"\"\"\n",
    "        \n",
    "        if fin - bgn <= self.time_steps:\n",
    "            patch_tuples_for_this_audio = [(bgn, fin, y)]\n",
    "            \n",
    "        else:\n",
    "            bgns = np.arange(bgn, fin - self.time_steps, self.hop_frames)\n",
    "            patch_tuples_for_this_audio = []\n",
    "            \n",
    "            for bgn in bgns:\n",
    "                patch_tuples_for_this_audio.append(\n",
    "                    (bgn, bgn + self.time_steps, y))\n",
    "                \n",
    "        return patch_tuples_for_this_audio\n",
    "    \n",
    "\n",
    "    def generate_train(self):\n",
    "        batch_size = self.batch_size\n",
    "        patch_bgn_fin_y_tuples = self.train_patch_bgn_fin_y_tuples.copy()\n",
    "        time_steps = self.time_steps\n",
    "        patches_num = len(patch_bgn_fin_y_tuples)\n",
    "        self.random_state.shuffle(patch_bgn_fin_y_tuples)\n",
    "        iteration = 0\n",
    "        pointer = 0\n",
    "        while True:\n",
    "            # Reset pointer\n",
    "            if pointer >= patches_num:\n",
    "                pointer = 0\n",
    "                self.random_state.shuffle(patch_bgn_fin_y_tuples)\n",
    "            # Get batch indexes\n",
    "            batch_patch_bgn_fin_y_tuples = patch_bgn_fin_y_tuples[\n",
    "                pointer: pointer + batch_size]    \n",
    "            pointer += batch_size\n",
    "            iteration += 1\n",
    "            (batch_x, batch_y) = self.get_batch_x_y(\n",
    "                self.x, batch_patch_bgn_fin_y_tuples)\n",
    "            # Transform data\n",
    "            batch_x = self.transform(batch_x)\n",
    "            yield batch_x, batch_y\n",
    "        \n",
    "    def get_batch_x_y(self, full_x, batch_patch_bgn_fin_y_tuples):\n",
    "        \"\"\"Get batch_x and batch_y, repeat is audio is short. \n",
    "        \"\"\"\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for (bgn, fin, y) in batch_patch_bgn_fin_y_tuples:\n",
    "            batch_y.append(y)\n",
    "            if fin - bgn == self.time_steps:\n",
    "                batch_x.append(full_x[bgn : fin])\n",
    "            else:\n",
    "                batch_x.append(repeat_seq(full_x[bgn : fin], self.time_steps))\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def generate_validate_slices(self, data_type, manually_verified_only, \n",
    "                                 shuffle, max_audios_num=None):\n",
    "        \"\"\"Generate patches in an audio. \n",
    "        Args:\n",
    "          data_type: 'train' | 'validate'\n",
    "          manually_verified_only: bool\n",
    "          shuffle: bool\n",
    "          max_audios_num: int, set maximum audios to speed up validation\n",
    "        \"\"\"\n",
    "        if data_type == 'train':\n",
    "            audio_indexes = np.array(self.train_audio_indexes)\n",
    "        elif data_type == 'validate':\n",
    "            audio_indexes = np.array(self.validate_audio_indexes)\n",
    "        else:\n",
    "            raise Exception('Incorrect data_type!')\n",
    "        if manually_verified_only:\n",
    "            manually_verified_indexes = np.where(\n",
    "                self.manually_verifications[audio_indexes]==1)[0]\n",
    "            audio_indexes = audio_indexes[manually_verified_indexes]\n",
    "        if shuffle:\n",
    "            self.validate_random_state.shuffle(audio_indexes)\n",
    "        for (n, audio_index) in enumerate(audio_indexes):\n",
    "            if n == max_audios_num:\n",
    "                break\n",
    "            [bgn, fin] = self.bgn_fin_indices[audio_index]\n",
    "            y = self.y[audio_index]\n",
    "            audio_name = self.audio_names[audio_index]\n",
    "            patch_tuples_for_this_audio = \\\n",
    "                self.get_patch_bgn_fin_y_tuples_for_an_audio(bgn, fin, y)\n",
    "            (batch_x_for_an_audio, _) = self.get_batch_x_y(\n",
    "                self.x, patch_tuples_for_this_audio)\n",
    "            batch_x_for_an_audio = self.transform(batch_x_for_an_audio)\n",
    "            yield batch_x_for_an_audio, y, audio_name\n",
    "                \n",
    "    def transform(self, x):\n",
    "        \"\"\"Transform data. \n",
    "        Args:\n",
    "          x: (batch_x, seq_len, freq_bins) | (seq_len, freq_bins)\n",
    "        Returns:\n",
    "          Transformed data. \n",
    "        \"\"\"\n",
    "\n",
    "        return scale(x, self.mean, self.std)\n",
    "            \n",
    "            \n",
    "class TestDataGenerator(DataGenerator):\n",
    "    \n",
    "    def __init__(self, dev_hdf5_path, test_hdf5_path, time_steps, \n",
    "                 test_hop_frames):\n",
    "        \"\"\"Test data generator. \n",
    "        Args:\n",
    "          dev_hdf5_path: str, path of development hdf5 file\n",
    "          test_hdf5_path: str, path of test hdf5 file\n",
    "          time_stes: int, number of frames of a logmel spectrogram patch\n",
    "          test_hop_frames: int\n",
    "        \"\"\"\n",
    "        super(TestDataGenerator, self).__init__(\n",
    "            hdf5_path=dev_hdf5_path, \n",
    "            batch_size=None, \n",
    "            time_steps=time_steps,\n",
    "            validation_csv=None)\n",
    "        self.test_hop_frames = test_hop_frames\n",
    "        global corrupted_files\n",
    "        self.corrupted_files = corrupted_files\n",
    "        # Load test data\n",
    "        load_time = time.time()\n",
    "        hf = h5py.File(test_hdf5_path, 'r')\n",
    "        self.test_audio_names = np.array([s.decode() for s in hf['filename'][:]])\n",
    "        self.test_x = hf['feature'][:]\n",
    "        self.test_bgn_fin_indices = hf['bgn_fin_indices'][:]\n",
    "        hf.close()\n",
    "        logging.info('Loading data time: {:.3f} s'.format(\n",
    "            time.time() - load_time))\n",
    "    \n",
    "    def generate_test_slices(self):\n",
    "        test_hop_frames = self.test_hop_frames\n",
    "        global corrupted_files\n",
    "        corrupted_files = corrupted_files\n",
    "        audio_indexes = range(len(self.test_audio_names))\n",
    "        for (n, audio_index) in enumerate(audio_indexes):\n",
    "            [bgn, fin] = self.test_bgn_fin_indices[audio_index]\n",
    "            audio_name = self.test_audio_names[audio_index]\n",
    "            if fin > bgn:\n",
    "                patch_tuples_for_this_audio = \\\n",
    "                    self.get_patch_bgn_fin_y_tuples_for_an_audio(bgn, fin, y=None)\n",
    "                (batch_x_for_an_audio, _) = \\\n",
    "                    self.get_batch_x_y(self.test_x, patch_tuples_for_this_audio)\n",
    "                batch_x_for_an_audio = self.transform(batch_x_for_an_audio)\n",
    "                yield batch_x_for_an_audio, audio_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config.py\n",
    "\n",
    "Este archivo define las variables necesarias para la ejecución del resto de funciones:\n",
    "\n",
    "- **sample_rate**: Especifica la tasa de muestreo de la señal de audio entrante. En este caso, es de 32000 muestras por segundo\n",
    "    -  - Referencia: [Librosa Mel Filters](https://librosa.org/doc/latest/generated/librosa.filters.mel.html)\n",
    "- **window_size**: Número de componentes FFT (2048 en este caso).\n",
    "  - Referencia: [Librosa Mel Filters](https://librosa.org/doc/latest/generated/librosa.filters.mel.html)\n",
    "- **overlap**: Número de puntos que se superpondrán entre segmentos del espectrograma (1024 muestras).\n",
    "  - Referencia: [SciPy Spectrogram](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html)\n",
    "- **mel_bins**: Número de bandas Mel a generar en el banco de filtros Mel. Esto genera una matriz de transformación lineal para proyectar los bins de FFT en bins de frecuencia Mel.\n",
    "  - Referencia: [Librosa Mel Filters](https://librosa.org/doc/latest/generated/librosa.filters.mel.html)\n",
    "- **labels**: Lista que contiene los nombres de las diferentes clases de sonidos.\n",
    "- **lb_to_ix**: Diccionario que mapea cada etiqueta de `labels` a su índice correspondiente.\n",
    "- **ix_to_lb**: Diccionario que mapea cada índice de `labels` a su etiqueta correspondiente.\n",
    "- **corrupted_files**: Lista que contiene los nombres de archivos de audio que se consideran corruptos o problemáticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 32000\n",
    "\n",
    "window_size = 2048\n",
    "overlap = 1024\n",
    "\n",
    "mel_bins = 64\n",
    "\n",
    "kmax = 3\n",
    "\n",
    "labels = ['Acoustic_guitar', 'Applause', 'Bark', 'Bass_drum', \n",
    "          'Burping_or_eructation', 'Bus', 'Cello', 'Chime', 'Clarinet', \n",
    "          'Computer_keyboard', 'Cough', 'Cowbell', 'Double_bass', \n",
    "          'Drawer_open_or_close', 'Electric_piano', 'Fart', 'Finger_snapping', \n",
    "          'Fireworks', 'Flute', 'Glockenspiel', 'Gong', 'Gunshot_or_gunfire', \n",
    "          'Harmonica', 'Hi-hat', 'Keys_jangling', 'Knock', 'Laughter', 'Meow', \n",
    "          'Microwave_oven', 'Oboe', 'Saxophone', 'Scissors', 'Shatter', \n",
    "          'Snare_drum', 'Squeak', 'Tambourine', 'Tearing', 'Telephone', \n",
    "          'Trumpet', 'Violin_or_fiddle', 'Writing']\n",
    "\n",
    "lb_to_ix = {lb: i for i, lb in enumerate(labels)}\n",
    "\n",
    "ix_to_lb = {i: lb for i, lb in enumerate(labels)}\n",
    "\n",
    "corrupted_files = ['0b0427e2.wav', '6ea0099f.wav', 'b39975f5.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_validation.py\n",
    "Este archivo contiene una única función destinada a la validación del modelo:\n",
    "- **create_validation_folds_**: Crea una estructura para realizar la validación cruzada, la cual se guarda en un archivo CSV llamado `validate_meta.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_folds(dataset_dir, workspace):\n",
    "    \"\"\"Create validation file with folds and write out to validate_meta.csv\n",
    "    \"\"\"\n",
    "    random_state = np.random.RandomState(1234)\n",
    "    folds_num = 4\n",
    "    # Paths\n",
    "    csv_path = os.path.join(dataset_dir, 'train.csv')\n",
    "    # Read csv\n",
    "    df = pd.DataFrame(pd.read_csv(csv_path))\n",
    "    indexes = np.arange(len(df))\n",
    "    random_state.shuffle(indexes)\n",
    "    audios_num = len(df)\n",
    "    audios_num_per_fold = int(audios_num // folds_num)\n",
    "    # Create folds\n",
    "    folds = np.zeros(audios_num, dtype=np.int32)\n",
    "    for n in range(audios_num):\n",
    "        folds[indexes[n]] = (n % folds_num) + 1\n",
    "    df_ex = df\n",
    "    df_ex['fold'] = folds\n",
    "    # Write out validation csv\n",
    "    out_path = os.path.join(workspace, 'validate_meta.csv')\n",
    "    df_ex.to_csv(out_path)\n",
    "    print(\"Write out to {}\".format(out_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecutará esta función especificando que los datos se encuentran en la ruta `./Data` (carpeta no incluida debido al gran tamaño)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write out to ./validate_meta.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./Data\"\n",
    "workspace = \"./\"\n",
    "create_validation_folds(dataset_dir, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features.py\n",
    "\n",
    "Este archivo contiene la clase `LogMelExtractor`, que se encarga de extraer las características de los audios.\n",
    "\n",
    "- **\\_\\_init\\_\\_**: Inicializa el extractor de características con los parámetros proporcionados y calcula el banco de filtros Mel.\n",
    "- **transform**: Transforma un fragmento de audio en características utilizando el logaritmo de la multiplicación del banco de filtros Mel con el espectrograma del mismo.\n",
    "- **calculate_logmel**: Lee un archivo de audio, lo normaliza y extrae sus características mediante el método `transform`.\n",
    "- **calculate_features**: Lee los audios de un archivo CSV, extrae las características para cada uno y escribe estas características junto con otros metadatos en un archivo HDF5. HDF son las siglas de Hierarchical Data Format (Formato de datos jerárquicos) y fue diseñado para guardar y recuperar datos de/hacia archivos grandes estructurados.\n",
    "  - Referencia: [HDF5 Manual](https://www.scayle.es/manual/es/hpc/software-instalado/hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMelExtractor():\n",
    "\n",
    "    def __init__(self, sample_rate, window_size, overlap, mel_bins):\n",
    "        self.window_size = window_size\n",
    "        self.overlap = overlap\n",
    "        self.ham_win = np.hamming(window_size)\n",
    "        self.melW = librosa.filters.mel(sr=sample_rate, \n",
    "                                        n_fft=window_size, \n",
    "                                        n_mels=mel_bins, \n",
    "                                        fmin=50., \n",
    "                                        fmax=sample_rate // 2).T\n",
    "    \n",
    "    def transform(self, audio):\n",
    "        ham_win = self.ham_win\n",
    "        window_size = self.window_size\n",
    "        overlap = self.overlap\n",
    "        [f, t, x] = signal.spectral.spectrogram(\n",
    "                        audio, \n",
    "                        window=ham_win,\n",
    "                        nperseg=window_size, \n",
    "                        noverlap=overlap, \n",
    "                        detrend=False, \n",
    "                        return_onesided=True, \n",
    "                        mode='magnitude') \n",
    "        x = x.T\n",
    "        x = np.dot(x, self.melW)\n",
    "        x = np.log(x + 1e-8)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "\n",
    "def calculate_logmel(audio_path, sample_rate, extractor):\n",
    "    (audio, _) = read_audio(audio_path, target_fs=sample_rate)\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    feature = extractor.transform(audio)\n",
    "    return feature\n",
    "\n",
    "def calculate_features(dataset_dir, workspace, data_type, mini_data):\n",
    "    \"\"\"Write features and infos of audios to a hdf5 file.\n",
    "    \"\"\"\n",
    "    global sample_rate\n",
    "    global window_size\n",
    "    global overlap\n",
    "    global mel_bins\n",
    "    global corrupted_files\n",
    "    # Paths\n",
    "    if data_type == 'development':\n",
    "        audio_dir = os.path.join(dataset_dir, 'audio_train')\n",
    "        meta_csv = os.path.join(dataset_dir, 'train.csv')\n",
    "    elif data_type == 'test':\n",
    "        audio_dir = os.path.join(dataset_dir, 'audio_test')\n",
    "        meta_csv = os.path.join(dataset_dir, 'sample_submission.csv')\n",
    "    if mini_data:\n",
    "        hdf5_path = os.path.join(workspace, 'features', 'logmel', \n",
    "                                 'mini_{}.h5'.format(data_type))\n",
    "    else:\n",
    "        hdf5_path = os.path.join(workspace, 'features', 'logmel', \n",
    "                                 '{}.h5'.format(data_type))\n",
    "    create_folder(os.path.dirname(hdf5_path))\n",
    "    # Load csv\n",
    "    df = pd.DataFrame(pd.read_csv(meta_csv))\n",
    "    audio_names = []\n",
    "    if data_type == 'development':\n",
    "        manually_verifications = []\n",
    "        target_labels = []\n",
    "    for row in df.iterrows():\n",
    "        audio_name = row[1]['fname']\n",
    "        audio_names.append(audio_name)\n",
    "        if data_type == 'development':\n",
    "            target_label = row[1]['label']\n",
    "            manually_verification = row[1]['manually_verified']\n",
    "            target_labels.append(target_label)\n",
    "            manually_verifications.append(manually_verification)\n",
    "    # Use partial data when set mini_data to True\n",
    "    if mini_data:\n",
    "        audios_num = 300\n",
    "        random_state = np.random.RandomState(0)\n",
    "        audio_indexes = np.arange(len(audio_names))\n",
    "        random_state.shuffle(audio_indexes)\n",
    "        audio_indexes = audio_indexes[0 : audios_num]\n",
    "        audio_names = [audio_names[idx] for idx in audio_indexes]\n",
    "        if data_type == 'development':\n",
    "            target_labels = [target_labels[idx] for idx in audio_indexes]\n",
    "            manually_verifications = [manually_verifications[idx] \n",
    "                                      for idx in audio_indexes]\n",
    "        print(\"Number of audios: {}\".format(len(audio_names)))\n",
    "    # Feature extractor\n",
    "    extractor = LogMelExtractor(sample_rate=sample_rate,\n",
    "                                window_size=window_size,\n",
    "                                overlap=overlap,\n",
    "                                mel_bins=mel_bins)\n",
    "    # Write out to h5 file\n",
    "    hf = h5py.File(hdf5_path, 'w')\n",
    "    hf.create_dataset(\n",
    "        name='feature',\n",
    "        shape=(0, mel_bins),\n",
    "        maxshape=(None, mel_bins),\n",
    "        dtype=np.float32)\n",
    "    calculate_time = time.time()\n",
    "    bgn_fin_indices = []\n",
    "    # Extract feature for audios\n",
    "    for (n, audio_name) in enumerate(audio_names):\n",
    "        # Extract feature\n",
    "        if audio_name in corrupted_files:\n",
    "            feature = np.zeros((0, mel_bins))\n",
    "        else:\n",
    "            audio_path = os.path.join(audio_dir, audio_name)\n",
    "            feature = calculate_logmel(audio_path, sample_rate, extractor)\n",
    "        # Write feature to hdf5\n",
    "        bgn_indice = hf['feature'].shape[0]\n",
    "        fin_indice = bgn_indice + feature.shape[0]\n",
    "        hf['feature'].resize((fin_indice, mel_bins))\n",
    "        hf['feature'][bgn_indice: fin_indice] = feature\n",
    "        bgn_fin_indices.append((bgn_indice, fin_indice))\n",
    "    # Write infos to hdf5\n",
    "    hf.create_dataset(name='filename', \n",
    "                      data=[s.encode() for s in audio_names], \n",
    "                      dtype='S32')\n",
    "    hf.create_dataset(name='bgn_fin_indices',\n",
    "                      data=bgn_fin_indices,\n",
    "                      dtype=np.int32)\n",
    "    if data_type == 'development':\n",
    "        hf.create_dataset(name='label', \n",
    "                          data=[s.encode() for s in target_labels], \n",
    "                          dtype='S32')\n",
    "        hf.create_dataset(name='manually_verification',\n",
    "                          data=manually_verifications,\n",
    "                          dtype=np.int32)\n",
    "    hf.close()\n",
    "    \n",
    "    print(\"Write out hdf5 file to {}\".format(hdf5_path))\n",
    "    print(\"Time spent: {} s\".format(time.time() - calculate_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el código, se crea la carpeta `features` donde se almacenan los archivos HDF5 llamado `development.h5` y `test.h5`. Sin embargo, esta carpeta no se incluye en el repositorio, ya que estos archivos son de gran tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gluar\\AppData\\Local\\Temp\\ipykernel_25704\\540075642.py:17: DeprecationWarning: Please import `spectrogram` from the `scipy.signal` namespace; the `scipy.signal.spectral` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  [f, t, x] = signal.spectral.spectrogram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write out hdf5 file to ./features\\logmel\\development.h5\n",
      "Time spent: 392.7382380962372 s\n"
     ]
    }
   ],
   "source": [
    "data_type = 'development'\n",
    "mini_data = False\n",
    "calculate_features(dataset_dir, workspace, data_type, mini_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gluar\\AppData\\Local\\Temp\\ipykernel_25704\\540075642.py:17: DeprecationWarning: Please import `spectrogram` from the `scipy.signal` namespace; the `scipy.signal.spectral` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  [f, t, x] = signal.spectral.spectrogram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write out hdf5 file to ./features\\logmel\\test.h5\n",
      "Time spent: 388.41344356536865 s\n"
     ]
    }
   ],
   "source": [
    "data_type = 'test'\n",
    "calculate_features(dataset_dir, workspace, data_type, mini_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos y funciones presentes en la carpeta `pytorch` son los siguientes:\n",
    "\n",
    "### model_pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
